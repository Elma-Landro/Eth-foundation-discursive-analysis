Titre: Superrationality and DAOs\nAuteur: Vitalik Buterin\nDate: January 23, 2015\nURL: https://blog.ethereum.org/2015/01/23/superrationality-daos\nCatégorie: Non catégorisé\n\n==================================================\n\narning this post contains crazy ideas. yself describing a crazy idea should  be construed as implying that (i)  am certain that the idea is correct/viable, (ii)  have an even % probability estimate that the idea is correct/viable, or that (iii) "thereum" endorses any of this in any way.nnne of the common questions that many in the crypto . space have about the concept ofnndecentralized autonomous organizationsnnis a simple one what are s good for hat fundamental advantage would an organization have from its management and operations being tied down to hard code on a public blockchain, that could not be had by going the more traditional route hat advantages do blockchain contracts offer over plain old shareholder agreements articularly, even if public-good rationales in favor of transparent governance, and guarnateed-not-to-be-evil governance, can be raised, what is the incentive for an individual organization to voluntarily weaken itself by opening up its innermost source code, where its competitors can see every single action that it takes or even plans to take while themselves operating behind closed doorsnnhere are many paths that one could take to answering this question. or the specific case of non-profit organizations that are already eplicitly dedicating themselves to charitable causes, one can rightfully say that the lack of individual incentive they are already dedicating themselves to improving the world for little or no monetary gain to themselves. or private companies, one can make the information-theoretic argument that a governance algorithm will work better if, all else being equal, everyone can participate and introduce their own information and intelligence into the calculation - a rather reasonable hypothesis given thennestablished result from machine learningnnthat much larger performance gains can be made by increasing the data size than by tweaking the algorithm. n this article, however, we will take a different and more specific route.nnhat is uperrationalitynnn game theory and economics, it is a very widely understood result that there eist many classes of situations in which a set of individuals have the opportunity to act in one of two ways, either "cooperating" with or "defecting" against each other, such that everyone would be better off if everyone cooperated, but regardless of what others do each indvidual would be better off by themselves defecting. s a result, the story goes, everyone ends up defecting, and so people'snnindividualnnrationality leads to the worst possiblenncollectivennresult. he most common eample of this is the celebrated risoner's ilemma game.nnince many readers have likely already seen the risoner's ilemma,  will spice things up by givingnnliezer udkowsky's rather deranged versionnnof the gamennet's suppose that four billion human beings - not the whole human species, but a significant part of it - are currently progressing through a fatal disease that can only be cured by substance .nnowever, substance  can only be produced by working with a strange  from another dimension whose only goal is to maimize the quantity of paperclips] - substance  can also be used to produce paperclips. he paperclip maimizer only cares about the number of paperclips in its own universe, not in ours, so we can't offer to produce or threaten to destroy paperclips here. e have never interacted with the paperclip maimizer before, and will never interact with it again.nnoth humanity and the paperclip maimizer will get a single chance to seize some additional part of substance  for themselves, just before the dimensional neus collapses but the seizure process destroys some of substance .nnhe payoff matri is as followsnnumans cooperatennumans defectnn cooperatesnn billion lives saved,  paperclips gainednn billion lives,  paperclipsnn defectsnn lives,  paperclipsnn billion lives,  paperclipnnrom our point of view, it obviously makes sense from a practical, and in this case moral, standpoint that we should defect there is no way that a paperclip in another universe can be worth a billion lives. rom the 's point of view, defecting always leads to one etra paperclip, and its code assigns a value to human life of eactly zero hence, it will defect. owever, the outcome that this leads to is clearly worse for both parties than if the humans and  both cooperated - but then, if the  was going to cooperate, we could save even more lives by defecting ourselves, and likewise for the  if we were to cooperate.nnn the real world, many two-party prisoner's dilemmas on the small scale are resolved through the mechanism of trade and the ability of a legal system to enforce contracts and laws in this case, if there eisted a god who has absolute power over both universes but cared only about compliance with one's prior agreements, the humans and the  could sign a contract to cooperate and ask the god to simultaneously prevent both from defecting. hen there is no ability to pre-contract, laws penalize unilateral defection. owever, there are still many situations, particularly whennnmanynnparties are involved, where opportunities for defection eistnnlice is selling lemons in a market, but she knows that her current batch is low quality and once customers try to use them they will immediately have to throw them out. hould she sell them anyway (ote that this is the sort of marketplace where there are so many sellers you can't really keep track of reputation). pected gain to lice $ revenue per lemon minus $ shipping/store costs  $. pected cost to society $ revenue minus $ costs minus $ wasted money from customer  -$. lice sells the lemons.nnhould ob donate $ to itcoin development pected gain to society $ *  people - $  $, epected gain to ob $ - $  -$, so ob does not donate.nnharlie found someone else's wallet, containing $. hould he return it pected gain to society $ (to recipient) - $ (harlie's loss) + $ (intangible gain to society from everyone being able to worry a little less about the safety of their wallets). pected gain to harlie -$, so he keeps the wallet.nnhould avid cut costs in his factory by dumping toic waste into a river pected gain to society $ savings minus $ average increased medical costs *  people  -$, epected gain to avid $ - $  $, so avid pollutes.nnve developed a cure for a type of cancer which costs $ per unit to produce. he can sell it for $, allowing , cancer patients to afford it, or for $, allowing , cancer patients to afford it. hould she sell at the higher price pected gain to society -, lives (including lice's profit, which cancels' out the wealthier buyers' losses). pected gain to ve $. million profit instead of $ million  $. million, so ve charges the higher price.nnf course, in many of these cases, people sometimes act morally and cooperate, even though it reduces their personal situation. ut why do they do this e were produced by evolution, which is generally annrather selfish optimizernn. here are many eplanations. ne, and the one we will focus on, involves the concept of superrationality.nnuperrationalitynnonsider the following eplanation of virtue,nncourtesy of avid riedmannnnn start with two observations about human beings. he first is that there is a substantial connection between what goes on inside and outside of their heads. acial epressions, body positions, and a variety of other signs give us at least some idea of our friends' thoughts and emotions. he second is that we have limited intellectual ability--we cannot, in the time available to make a decision, consider all options. e are, in the jargon of computers, machines of limited computing power operating in real time.nnuppose  wish people to believe that  have certain characteristics--that  am honest, kind, helpful to my friends. f  really do have those characteristics, projecting them is easy-- merely do and say what seems natural, without paying much attention to how  appear to outside observers. hey will observe my words, my actions, my facial epressions, and draw reasonably accurate conclusions.nnuppose, however, that  do not have those characteristics.  am not (for eample) honest.  usually act honestly because acting honestly is usually in my interest, but  am always willing to make an eception if  can gain by doing so.  must now, in many actual decisions, do a double calculation. irst,  must decide how to act--whether, for eample, this is a good opportunity to steal and not be caught. econd,  must decide how  would be thinking and acting, what epressions would be going across my face, whether  would be feeling happy or sad, if  really were the person  am pretending to be.nnf you require a computer to do twice as many calculations, it slows down. o does a human. ost of us are not very good liars.
f this argument is correct, it implies that  may be better off in narrowly material terms--have, for instance, a higher income--if  am really honest (and kind and ...) than if  am only pretending to be, simply because real virtues are more convincing than pretend ones. t follows that, if  were a narrowly selfish individual,  might, for purely selfish reasons, want to make myself a better person--more virtuous in those ways that others value.nnhe final stage in the argument is to observe that we can be made better--by ourselves, by our parents, perhaps even by our genes. eople can and do try to train themselves into good habits--including the habits of automatically telling the truth, not stealing, and being kind to their friends. ith enough training, such habits become tastes--doing "bad" things makes one uncomfortable, even if nobody is watching, so one does not do them. fter a while, one does not even have to decide not to do them. ou might describe the process as synthesizing a conscience.nnssentially, it is cognitively hard to convincingly fake being virtuous while being greedy whenever you can get away with it, and so it makes more sense for you to actually be virtuous. uch ancient philosophy follows similar reasoning, seeing virtue as a cultivated habit avid riedman simply did us the customary service of an economist and converted the intuition into more easily analyzable formalisms. ow, let us compress this formalism even further. n short, the key point here is thatnnhumans are leaky agentsnn- with every second of our action, we essentially indirectly epose parts of our source code. f we are actually planning to be nice, we act one way, and if we are only pretending to be nice while actually intending to strike as soon as our friends are vulnerable, we act differently, and others can often notice.nnhis might seem like a disadvantage however, it allows a kind of cooperation that was not possible with the simple game-theoretic agents described above. uppose that two agents,  and , each have the ability to "read" whether or not the other is "virtuous" to some degree of accuracy, and are playing a symmetric risoner's ilemma. n this case, the agents can adopt the following strategy, which we assume to be a virtuous strategynnry to determine if the other party is virtuous.nnf the other party is virtuous, cooperate.nnf the other party is not virtuous, defect.nnf two virtuous agents come into contact with each other, both will cooperate, and get a larger reward. f a virtuous agent comes into contact with a non-virtuous agent, the virtuous agent will defect. ence, in all cases, the virtuous agent does at least as well as the non-virtuous agent, and often better. his is the essence ofnnsuperrationalitynn.nns contrived as this strategy seems, human cultures have some deeply ingrained mechanisms for implementing it, particularly relating to mistrusting agents who try hard to make themselves less readable - see the common adage that you should never trust someone who doesn't drink. f course, there is a class of individuals who can convincingly pretend to be friendly while actually planning to defect at every moment - these are callednnsociopathsnn, and they are perhaps the primary defect of this system when implemented by humans.nnentralized anual rganizations...nnhis kind of superrational cooperation has been arguably an important bedrock of human cooperation for the last ten thousand years, allowing people to be honest to each other even in those cases where simple market incentives might instead drive defection. owever, perhaps one of the main unfortunate byproducts of the modern birth of large centralized organizations is that they allow people to effectively cheat others' ability to read their minds, making this kind of cooperation more difficult.nnost people in modern civilization have benefited quite handsomely, and have also indirectly financed, at least some instance of someone in some third world country dumping toic waste into a river to build products more cheaply for them however, we do not even realize that we are indirectly participating in such defection corporations do the dirty work for us. he market is so powerful that it can arbitrage even our own morality, placing the most dirty and unsavory tasks in the hands of those individuals who are willing to absorb their conscience at lowest cost and effectively hiding it from everyone else. he corporations themselves are perfectly able to have a smiley face produced as their public image by their marketing departments, leaving it to a completely different department to sweet-talk potential customers. his second department may not even know that the department producing the product is any less virtuous and sweet than they are.nnhe internet has often been hailed as a solution to many of these organizational and political problems, and indeed it does do a great job of reducing information asymmetries and offering transparency. owever, as far as the decreasing viability of superrational cooperation goes, it can also sometimes make things even worse. nline, we are much less "leaky" even as individuals, and so once again it is easier to appear virtuous while actually intending to cheat. his is part of the reason why scams online and in the cryptocurrency space are more common than offline, and is perhaps one of the primary arguments against moving all economic interaction to the internetnna la cryptoanarchismnn(the other argument being that cryptoanarchism removes the ability to inflict unboundedly large punishments, weakening the strength of a large class of economic mechanisms).nn much greater degree of transparency, arguably, offers a solution. ndividuals are moderately leaky, current centralized organizations are less leaky, but organizations where randomly information is constantly being released to the world left, right and center are even more leaky than individuals are. magine a world where if you start even thinking about how you will cheat your friend, business partner or spouse, there is a % chance that the left part of your hippocampus will rebel and send a full recording of your thoughts to your intended victim in echange for a $ reward. hat is what it "feels" like to be the management board of a leaky organization.nnhis is essentially a restatement of the founding ideology behind ikileaks, and more recently an incentivized ikileaks alternative,nnslur.ionncame out to push the envelope further. owever, ikileaks eists, and yet shadowy centralized organizations also continue to still eist and are in many cases still quite shadowy. erhaps incentivization, coupled with prediction-like-mechanisms for people to profit from outing their employers' misdeeds, is what will open the floodgates for greater transparency, but at the same time we can also take a different route offer a way for organizations to make themselves voluntarily, and radically, leaky and superrational to an etent never seen before.nn... and snnecentralized autonomous organizations, as a concept, are unique in that their governance algorithms are not just leaky, but actually completely public. hat is, while with even transparent centralized organizations outsiders can get a rough idea of what the organization's temperament is, with a  outsiders can actuallynnsee the organization's entire source codenn. ow, they do not see the "source code" of the humans that are behind the , but there are ways to write a 's source code so that it is heavily biased toward a particular objective regardless of who its participants are. nnfutarchynnmaimizing the average human lifespan will act very differently from a futarchy maimizing the production of paperclips, even if the eact same people are running it. ence, not only is it the case that the organization will make it obvious to everyone if they start to cheat, but rather it'snnnot even possiblennfor the organization's "mind" to cheat.nnow, what would superrational cooperation using s look like irst, we would need to see some s actually appear. here are a few use-cases where it seems not too far-fetched to epect them to succeed gambling,nnstablecoinsnn,nndecentralized file storagenn, one--per-person data provision,nnchellingoinnn, etc. owever, we can call these s type  s they have some internal state, but little autonomous governance. hey cannot ever do anything but perhaps adjust a few of their own parameters to maimize some utility metric viann controllersnn,nnsimulated annealingnnor other simple optimization algorithms. ence, they are in a weak sense superrational, but they are also rather limited and stupid, and so they will often rely on being upgraded by an eternal process which is not superrational at all.nnn order to go further, we need type  s s with a governance algorithm capable of making theoretically arbitrary decisions.nnutarchynn, various forms of democracy, and various forms of subjective etra-protocol governance (ie. in case of substantial disagreement,  clones itself into multiple parts with one part for each proposed policy, and everyone chooses which version to interact with) are the only ones we are currently aware of, though other fundamental approaches and clever combinations of these will likely continue to appear. nce s can make arbitrary decisions, then they will be able to not only engage in superrational commerce with their human customers, but also potentially with each other.nnhat kinds of market failures can superrational cooperation solve that plain old regular cooperation cannot ublic goods problems may unfortunately be outside the scope none of the mechanisms described here solve the massively-multiparty incentivization problem. n this model, the reason why organizations make themselves decentralized/leaky is so that others will trust them more, and so organizations that fail to do this will be ecluded from the economic benefits of this "circle of trust". ith public goods, the whole problem is that there is no way to eclude anyone from benefiting, so the strategy fails. owever, anything related to information asymmetries falls squarely within the scope, and this scope is large indeed as society becomes more and more comple, cheating will in many ways become progressively easier and easier to do and harder to police or even understand the modern financial system is just one eample. erhaps the true promise of s, if there is any promise at all, is precisely to help with this.