Titre: On Stake\nAuteur: Vitalik Buterin\nDate: July 5, 2014\nURL: https://blog.ethereum.org/2014/07/05/stake\nCatégorie: Non catégorisé\n\n==================================================\n\nhe topic of mining centralization has been a very important one over the past few weeks. .io, the itcoin network's largest mining pool, has for the past month directednnover %nnof the itcoin network's hashpower, and two weeks ago briefly spiked over %, theoretically giving it monopoly control over the itcoin network. lthough miners quidkly left the pool and reduced its hashpower to %, it's clear that the problem is not solved. t the same time, s threaten to further centralize the very production . ne approach to solving the problem is thennone  advocated in my previous postnn create a mining algorithm that is guaranteed to remain -friendly in the long term. nother, however, is to abolish mining entirely, and replace it with a new model for seeking consensus.nnhe primary second contender to date has been a strategy called "proof of stake", the intuition behind which is as follows. n a traditional proof-of-work blockchain, miners "vote" on which transactions came at what time with their  power, and the more  power you have the proportionately larger your influence is. n proof-of-stake, the system follows a similar but different paradigm stakeholders vote with their dollars (or rather, the internal currency of the particular system). n terms of how this works technically, the simplest setup is a model that has been called the "simulated mining rig" essentially, every account has a certain chance per second of generating a valid block, much like a piece of mining hardware, and this chance is proportional to the account's balance. he simplest formula for this isnnnn(nnprevhash + address + timestampnn)nnnnnn^ * balance /nndiffnnprevhashnnis the hash of the previous block,nnaddressnnis the address of the stake-miner,nntimestampnnis the current ni time in second,nnbalancennis the account balance of the stack-miner andnndiffnnis an adjustable global difficulty parameter. f a given account satisfies this equation at any particular second, it may produce a valid block, giving that account some block reward.nnnother approach is to use not the balance, but the "coin age" (ie. the balance multiplied by the amount of time that the coins have not been touched), as the weighting factor this guarantees more even returns but at the epense of potentially much easier collusion attacks, since attackers have the ability to accumulate coin age, and possible superlinearity for these reasons,  prefer the plain balance-based approach in most cases, and we will use this as our baseline for the rest of this discussion.nnther solutions to "proof of " have been proposed, including ecellence, bandwidth, storage and identity, but none are particularly convenient asnnconsensusnnalgorithms rather, all of these systems have many of the same properties of proof of stake, and are thus best implemented indirectly - by making them purely mechanisms for currency distribution, and then using proof of stake on those distributed coins for the actual consensus. he only eception is perhaps the social-graph-theory based ipple, although many cryptocurrency proponents consider such systems to be far too trust-dependent in order to be considered truly "decentralized" this point can be debated, but it is best to focus on one topic at a time and so we will focus on stake.nntrengths and eaknessesnnf it can be implemented correctly, in theory proof of stake has many advantages. n particular are threennt does not waste any significant amount of electicity. ure, there is a need for stakeholders to keep trying to produce blocks, but no one gains any benefit from making more than one attempt per account per second hence, the electricity ependiture is comparable to any other non-wasteful internet protocol (eg. itorrent)nnt can arguably provide a much higher level of security. n proof of work, assuming a liquid market for computing power the cost of launching a % attack is equal to the cost of the computing power of the network over the course of two hours - an amount that, by standard economic principles, is roughly equal to the total sum of block rewards and transaction fees provided in two hours. n proof of stake, the threshold is theoretically much higher % of the entire supply of the currency.nnepending on the precise algorithm in question it can potentially allow for much faster blockchains (eg.  has one block every few seconds, compared to one per minute for thereum and one per ten minutes for itcoin)nnote that there is one important counterargument that has been made to # if a large entity credibly commits to purchasing % of currency units and then using those funds to repeatedly sabotage the network, then the price will fall drastically, making it much easier for that entity to puchase the tokens. his does somewhat mitigate the benefit of stake, although not nearly fatally an entity that can credibly commit to purchasing % of coins is likely also one that can launch % attacks against proof of work.nnowever, with the naive proof of stake algorithm described above, there is one serious problem as some itcoin developers describe it, "there is nothing at stake". hat that means is this in the contet of a proof-of-work blockchain, if there is an accidental fork, or a deliberate transaction reversal ("double-spend") attempt, and there are two competing forks of the blockchain, then miners have to choose which one they contribute to. heir three choices are eithernnine on no chain and get no rewardsnnine on chain  and get the reward if chain  winsnnine on chain  and get the reward if chain  winsnns  have commented in annprevious postnn, note the striking similarity to chellingoin/ruthcoin here you win if you go with what everyone else goes with, ecept in this case the vote is on the order of transactions, not a numerical (as in chellingoin) or binary (as in ruthoin) datum. he incentive is to support the chain that everyone else supports, forcing rapid convergence, and preventing successful attacks provided that at least % of the network is not colluding.nnn the naive proof of stake algorithm, on the other hand, the choices of whether or not to vote on  and whether or not to vote on  are independent hence, the optimal strategy is to mine on any fork that you can find. hus, in order to launch a successful attack, an attacker need only overpower all of the altruists who are willing to vote only on the correct chain.nnhe problem is, unfortunately, somewhat fundamental. roof of work is nice because the property of hash verification allows the network to be aware of something outside of itself - namely, computing power, and that thing serves as a sort of anchor to ensure some stability. n a naive proof of stake system, however, the only thing that each chain is aware of is itself hence, one can intuitively see that this makes such systems more flimsy and less stable. owever, the above is merely an intuitive argument it is by no means a mathematical proof that a proof-of-stake system cannot be incentive-compatible and secure, and indeed there are a number of potential ways to get around the issue.nnhe first strategy is the one that is employed in thennlashernnalgorithm, and it hinges on a simple realization although, in the case of a fork, chains are not aware of anything in the outside world, they are aware of each other. ence, the way the protocol prevents double-mining is this if you mine a block, the reward is locked up for  blocks, and if you also mine on any other chain then anyone else can submit the block from the other chain into the original chain in order to steal the mining reward. ote, however, that things are not quite so simple, and there is one catch the miners have to be known in advance. he problem is that if the algorithm given above is used directly, then the issue arises that, using a probabilistic strategy, double mining becomes very easy to hide.nnhe issue is this suppose that you have % stake, and thus every block there is a % chance that you will be able to produce (hereinafter, "sign") it. ow, suppose there is a fork between chain  and chain , with chain  being the "correct" chain. he "honest" strategy is to try to generate blocks just on , getting an epected . -coins per block. n alternative strategy, however, is to try to generate blocks on both  and , and if you find a block on both at the same time then discarding . he payout per block is one -coin if you get lucky on  (.% chance), one -coin if you get lucky on  (.% chance) and one -coin, but no -coins, if you get lucky on both hence, the epected payout is . -coins plus . -coins if you double-vote. f the stakeholders that need to sign a particular block are decided in advance, however (ie. specifically, decided before a fork starts), then there is no possibility of having the opportunity to vote on  but not  you either have the opportunity on both or neither. ence, the "dishonest" strategy simply collapses into being the same thing as the "honest" strategy.nnhe lock igner election roblemnnut then if block signers are decided in advance, another issue arises if done wrong, block signers could "mine" their blocks, repeatedly trying to create a block with different random data until the resulting block triggers that same signer having the privilege to sign a block again very soon. or eample, if the signer for block + was simply chosen from the hash of block , and an attacker had % stake, then the attacker could keep rebuilding the block until block + also had the attacker as its signer (ie. an epected  iterations). ver time, the attacker would naturally gain signing privilege on other blocks, and thus eventually come to completely saturate the blockchain with length- cycles controlled by himself. ven if the hash of  blocks put together is used, it's possible to manipulate the value. hus, the question is, how do we determine what the signers for future blocks are going to bennhe solution used in lasher is to use a secure decentralized random number generator protocol many parties come in, first submit to the blockchain the hashes of their values, and then submit their values. here is no chance of manipulation this way, because each submitter is bound to submit in the second round the value whose hash they provided in the first round, and in the first round no one has enough information in order to engage in any manipulation. he player still has a choice of whether or not to participate in the second round, but the two countervailing points are that () this is only one bit of freedom, although it becomes greater for large miners that can control multiple accounts, and () we can institute a rule that failing to participate causes forfeiture of one's mining privilege (miners in round  choose miners for round + during round -, so there is an opportunity to do this if certain round- miners misbehave during this selection step).nnnother idea, proposed by ddo entov and others in their "nnryptocurrencies ithout roof of orknn" paper, is to use something called a "low-influence" function - essentially, a function such that there is only a very low chance that a single actor will be able to change the result by changing the input.  simple eample of an  over small sets is majority rule here, because we are trying to pick a random miner, we have a very large set of options to choose from, so majority rule per bit is used (eg. if you have  parties and you want to pick a random miner out of a billion, assign them into thirty groups of , and have each group vote on whether their particular bit is zero or one, and then recombine the bits as a binary number at the end). his removes the need for a complicated two-step protocol, allowing it to potentially be done much more quickly and even in parallel, reducing the risk that the pre-chosen stake-miners for some particular block will get together and collude.nn third interesting strategy, used by , is to use the addresses of the stake-miners for blocks  and + to choose the miner for block + this by definition gives only one choice for the net miner in each block. dding a criterion that every miner needs to be locked in for  blocks in order to participate prevents sending transactions as a form of double-mining. owever, having such rapid stake-miner selection also compromises the nothing-at-stake resistance property due to the probabilistic double-mining problem this is the reason why clever schemes to make miner determination happen very quickly are ultimately, beyond a certain point, undesirable.nnong-ange ttacksnnhile the lasher approach does effectively solve the nothing-at-stake problem against traditional % attacks, a problem arises in the case of something called a "long-range attack" instead of an attacker starting mining from ten blocks before the current block, the attacker starts ten thousand blocks ago. n a proof-of-work contet, this is silly it basically means doing thousands of times as much work as is necessary to launch an attack. ere, however, creating a block is nearly computationally free, so it's a reasonable strategy. he reason why it works is that lasher's process for punishing multi-mining only lasts for  blocks, and its process for determining new miners lasts  blocks, so outside the "scope" of that range lasher functions eactly like the naive proof-of-stake coin. ote that lasher is still a substantial improvement in fact, assuming users never change it can be made fully secure by introducing a rule into each client not to accept forks going back more than  blocks. he problem is, however, what happens when a new user enters the picture.nnhen a new user downloads a proof-of-stake-coin client for the first time, it will see multiple versions of the blockchain the longest, and therefore legitimate, fork, and many pretenders trying to mine their own chains from the genesis. s described above, proof-of-stake chains are completely self-referential hence, the client seeing all of these chains has no idea about any surrounding contet like which chain came first or which has more value (note in a hybrid proof-of-stake plus social graph system, the user would get initial blockchain data from a trusted source this approach is reasonable, but is not fully decentralized). he only thing that the client can see is the allocation in the genesis block, and all of the transactions since that point. hus, all "pure" proof-of-stake systems are ultimately permanent nobilities where the members of the genesis block allocation always have the ultimate say. o matter what happens ten million blocks down the road, the genesis block members can always come together and launch an alternate fork with an alternate transaction history and have that fork take over.nnf you understand this, and you are still okay with pure proof of stake as a concept (the specific reason why you might still be okay is that, if the initial issuance is done right, the "nobility" should still be large enough that it cannot practically collude), then the realization allows for some more imaginative directions in terms of how proof of stake can play out. he simplest idea is to have the members of the genesis block vote on every block, where double-mining is punished by permanent loss of voting power. ote that this system actually solves nothing-at-stake issues completely, since every genesis block holder has a mining privilege that has value forever into the future, so it will always not be worth it to double-mine. his system, however, has a finite lifespan - specifically, the maimum life (and interest) span of the genesis signers, and it also gives the nobility a permanent profit-making privilege, and not just voting rights however, nevertheless the eistence of the algorithm is encouraging because it suggests that long-range-nothing-at-stake might be fundamentally resolvable. hus, the challenge is to figure out some way to make sure voting privileges transfer over, while still at the same time maintaining security.nnhanging ncentivesnnnother approach to solving nothing-at-stake comes at the problem from a completely different angle. he core problem is, in naive proof-of-stake, rational individuals will double-vote. he lasher-like solutions all try to solve the problem by making it impossible to double-vote, or at the very least heavily punishing such a strategy. ut what if there is another approach specifically, what if we instead remove the incentive to do so n all of the proof of stake systems that  described above, the incentive is obvious, and unfortunately fundamental because whoever is producing blocks needs an incentive to participate in the process, they benefit if they include a block in as many forks as possible. he solution to this conundrum comes from an imaginative, out-of-the-bo proposal from aniel arimernntransactions as proof of stakenn.nnhe core idea behind transactions as proof-of-stake is simple instead of mining being done by a separate class of individuals, whether computer hardware owners or stakeholders, mining and transaction sending are merged into one. he naive ao algorithm is as followsnnvery transaction must contain a reference (ie. hash) to the previous transactionnn candidate state-of-the-system is obtained by calculating the result of a resulting transaction chainnnhe correct chain among multiple candidates is the one that has either (i) the longest coin-days-destroyed (ie. number of coins in the account * time since last access), or (ii) the highest transaction fees (these are two different options that we will analyze separately)nnhis algorithm has the property that it is etremely unscalable, breaking down beyond about  transaction per - seconds, and it is not the one that arimer suggests or the one that will actually be used rather, it's simply a proof of concept that we will analyze to see if this approach is valid at all. f it is, then there are likely ways to optimize it.nnow, let's see what the economics of this are. uppose that there is a fork, and there are two competing versions of the ao chain. ou, as a transaction sender, made a transaction on chain , and there is now an upcoming chain . o you have the incentive to double-mine and include your transaction in chain  as well he answer is no - in fact you actually want to double-spend your recipient so you would not put the transaction on another chain. his argument is especially potent in the case of long-range attacks, where you already received your product in echange for the funds in the short term, of course, the incentive still eists to make sure the transaction is sent, so senders do have the incentive to double-mine however, because the worry is strictly time-limited this can be resolved via a lasher-like mechanism.nnne concern is this given the presence of forks, how easy is it to overwhelm the system f, for eample, there is a fork, and one particular entity wants to double-spend, under what circumstances is that possible n the transaction-fee version, the requirement is pretty simple you need to spend more tfees than the rest of the network. his seems weak, but in reality it isn't we know that in the case of itcoin, once the currency supply stops increasing mining will rely solely on transaction fees, and the mechanics are eactly the same (since the amount that the network will spend on mining will roughly correspond to the total number of tfees being sent in) hence, fee-based ao is in this regard at least as secure as fee-only o mining. n the second case, we have a different model instead of mining with your coins, you are mining with your liquidity. nyone can % attack the system if and only if they have a sufficiently large quantity of coin-days-destroyed on them. ence, the cost of spending a large tfee after the fact is replaced by the cost of sacrificing liquidity before the fact.nnost of iquiditynnhe discussion around liquidity leads to another important philosophical point security cannot be cost-free. n any system where there is a block reward, the thing that is the prerequisite for the reward (whether , stake, or something else) cannot be free, since otherwise everyone would be claiming the reward at infinitum, and in ao transaction senders need to be providing some kind of fee to justify security. urthermore, whatever resource is used to back the security, whether , currency sacrifices or liquidity sacrifices, the attacker need only get their hands on the same quantity of that resource than the rest of the network. ote that, in the case of liquidity sacrifices (which is what naive proof of stake is), the relevant quantity here is actually not % of coins, but rather the privilege of accessing % of coins for a few hours - a service that, assuming a perfectly efficient market, might only cost a few hundred thousand dollars.nnhe solution to this puzzle is that marginal cost is not the same thing as average cost. n the case of proof of work, this is true only to a very limited etent although miners do earn a positive nonzero profit from mining, they all pay a high cost (unless they're  miners heating their homes, but even there there are substantial efficiency losses laptops running hash functions at %, though effective at heating, are necessarily less effective than systems designed for the task). n the case of currency sacrifices, everyone pays the same, but the payment is redistributed as a dividend to everyone else, and this profit is too dispersed to be recovered via market mechanisms thus, although the system is costly from a local perspective, it is costless from a global perspective.nnhe last option, liquidity sacrifice, is in between the two. lthough liquidity sacrifice is costly, there is a substantial amount of disparity in how much people value liquidity. ome people, like individual users or businesses with low savings, heavily value liquidity others, like savers, do not value liquidity at all (eg.  could not care less if  lost the ability to spend ten of my bitcoins for some duration). ence, although the marginal cost of liquidity will be high (specifically, necessarily equal to either the mining reward or the transaction fee), the average cost is much lower. ence, there is a leverage effect that allows the cost of an attack to be much higher than the inefficiency of the network, or the amount that senders spend on tfees. dditionally, note that in arimer's scheme specifically, things are rigged in such a a way thatnnallnnliquidity that is sacrificed in consensus is liquidity that was being sacrificed anyway (namely, by not sending coins earlier), so the practical level of inefficiency is zero.nnow, ao does have its problems. irst, if we try to make it more scalable by reintroducing the concept of blocks, then there ideally needs to be some reason to produce blocks that is not profit, so as not to reintroduce the nothing-at-stake problem. ne approach may be to force a certain class of large transaction senders to create blocks. econd, attacking a chain is still theoretically "cost-free", so the security assurances are somewhat less nice than they are in proof-of-work. hird, in the contet of a more complicated blockchain like thereum, and not a currency, some transactions (eg. finalizing a bet) are actually profitable to send, so there will be incentive to double-mine on at least some transactions (though not nearly all, so there is still some security). inally, it's a genesis-block-nobility system, just like all proof-of-stake necessarily is. owever, as far as pure proof-of-stake systems go, it does seem a much better backbone than the version of proof of stake that emulated itcoin mining.nnybrid roof of takenniven the attractiveness of proof of stake as a solution for increasing efficiency and security, and its simultaneous deficiencies in terms of zero-cost attacks, one moderate solution that has been brought up many times is hybrid proof of stake, in its latest incantation called "nnproof of activitynn". he idea behind proof of activity is simple blocks are produced via proof of work, but every block randomly assigns three stakeholders that need to sign it. he net block can only be valid once those signatures are in place. n this system, in theory, an attacker with % stake would see  of his  blocks not being signed, whereas in the legitimate network  out of  blocks would be signed hence, such an attacker would be penalized in mining by a factor of .nnowever, there is a problem what motivates signers to sign blocks on only one chain f the arguments against pure proof of stake are correct, then most rational stake-miners would sign both chains. ence, in hybrid o, if the attacker signs only his chain, and altruists only sign the legitimate chain, and everyone else signs both, then if the attacker can overpower the altruists on the stake front that means that the attacker can overtake the chain with less than a % attack on the mining front. f we trust that altruists as a group are more powerful in stake than any attacker, but we don't trust that too much, then hybrid o seems like a reasonable hedge option however, given the reasoning above, if we want to hybridize one might ask if hybrid o + ao might not be the more optimal way to go. or eample, one could imagine a system where transactions need to reference recent blocks, and a blockchain's score is calculated based on proof of work and coin-days-destroyed counts.nnonclusionnnill we see proof of stake emerge as a viable alternative to proof of work in the net few years t may well be. rom a pure efficiency perspective, if itcoin, or thereum, or any other o-based platform get to the point where they have similar market cap to gold, silver, the ,  or , or any other mainstream asset, then over a hundred billion dollars worth of new currency units will be produced per year. nder a pure-o regime, an amount of economic power approaching that will be spent on hashing every year. hus, the cost to society of maintaining a proof-of-work cryptocurrency is about the same as the cost of maintaining the ussian military (the analogy is particularly potent because militaries are also proof of work their only value to anyone is protecting against other militaries). nder hybrid-o, that might safely be dropped to $ billion per year, and under pure o it would be almost nothing, ecept depending on implementation maybe a few billion dollars of cost from lost liquidity.nnltimately, this boils down to a philosophical question eactly how much does decentralization mean to us, and how much are we willing to pay for it emember that centralized databases, and even quasi-centralized ones based on ipple consensus, are free. f perfect decentralization is indeed worthnnnnbnninnlnnlnninnonnnnn,nntnnhnnennnnnpnnrnnonnonnfnnonnfnnwnnonnrnnknninnsnndnnennfnninnnnninntnnennlnnynntnnhnnennrnninngnnhnntnnwnnannynntnnonngnnonn.nnnnunntnnannrnngnnunnannbnnlnnynntnnhnnanntnninnsnnnnnonntnntnnhnnenncnnannsnnenn.nnnnhnnanntnninnfnnsnnonncnninnenntnnynndnnonnennsnnnnnonntnnsnnennenndnnenncnnennnnntnnrnnannlnninnznnanntnninnonnnnnannsnnanngnnonnannlnninnnnninntnnsnnennlnnfnn,nnannnnndnntnnhnnennonnnnnlnnynnrnnennannsnnonnnnnwnnhnnynninntnn′nnsnnwnnonnrnntnnhnninntnntnnonndnnenncnnennnnntnnrnnannlnninnznnenninnsnntnnonngnnenntnntnnhnnenninnnnncnnrnnennannsnnenndnnbnnennnnnennfnninntnnsnnonnfnnennfnnfnninncnninnennnnncnnynntnnhnnanntnndnnenncnnennnnntnnrnnannlnninnznnanntnninnonnnnnbnnrnninnnnngnnsnnnnnnnnntnnhnnanntnncnnannsnnenn,nninnfnndnnenncnnennnnntnnrnnannlnninnznnanntnninnonnnnncnnonnmnnennsnnwnninntnnhnnann billion, then proof of work is definitely the right way to go. ut arguably that is not the case. hat if society does not see decentralization as a goal in itself, and the only reason why it's worth it to decentralize is to get the increased benefits of efficiency that decentralization brings n that case, if decentralization comes with annnnbinnllnninnonnnnn,nntnnhnnennnnnpnnroonnfnnonnfnnwnnornnkinnsnndnnennfnnininntnnennlnnynntnnhnnernninngnnhnntwnnannynntnnonngnnonn.nnnnunntnnannrnngunnabnnlnnynntnnhanntnninnsnnnnnonnttnnhnnecnnannsenn.nnhanntnninnfnnsocnninnenntnnynndnnoesnnnnnonntnnseenndnnecennnnntnnrnnannlnninnznnanntnninnonnnannsnnanngnnonnannlnnininntnnsennlnnfnn,nnannndnntnnhnneonnnnnlnnyrennannsonnnnnwnnhnnynninntnn′nnsnnwnnornntnnhinnttnnonndnnecennnnntnnrnnannlnninnzenninnsnntnnonngnnennttnnhnnenninnncrennannsenndnnbnnennnnnennfnninntnnsonnfnnennffnninncnninnennnnncynntnnhanntnndnnecennnnntnnrnnannlnninnznnanntnninnonnnbnnrnninnngnnsnnnnnnnnntnnhanntnncnnannsenn,nninnfdnnecennnnntnnrnnannlnninnznnanntnninnonnnnnconnmnnesnnwnninntnnhann billion price tag, then we should just centralize and let a few governments run the databases. ut if we have a solid, viable proof of stake algorithm, then we have a third option a system which is both decentralized and cost-free (note that useful proof of work also fits this criterion, and may be easier) in that case, the dichotomy does not eist at all and decentralization becomes the obvious choice.