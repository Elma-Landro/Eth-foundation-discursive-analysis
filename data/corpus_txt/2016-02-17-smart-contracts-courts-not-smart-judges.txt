Titre: From Smart Contracts to Courts with not so Smart Judges\nAuteur: Christian Reitwiessner\nDate: February 17, 2016\nURL: https://blog.ethereum.org/2016/02/17/smart-contracts-courts-not-smart-judges\nCatégorie: Non catégorisé\n\n==================================================\n\nthereum is often described as a platform for self-enforcing smart contracts. hile this is certainly true, this article argues that, especially when more comple systems are involved, it is rather a court with smart lawyers and a judge that is not so smart, or more formally, a judge
with restricted computational resources. e will see later how this view can be leveraged to write very efficient smart contract systems, to the etent that cross-chain token transfers or computations like checking proof of work can be implemented at almost no cost.nnhe ourt nalogynnirst of all, you probably know that a smart contract on thereum cannot in itself retrieve information from the outside world. t can only ask outside actors to deliver information on its behalf. nd even then, it either has to trust the outside actors or verify the integrity of the information itself. n court, the judge usually asks eperts about their opinion (who they usually trust) or witnesses for a testimony that is often verified by cross-checking.nn guess it is obvious that the computational resources of the judge in thereum are restricted due to the gas limit, which is rather low when compared to the computational powers of the lawyers coming from the outside world. et, a judge restricted in such a way can still decide on very complicated legal cases er powers come from the fact that she can play off the defender against the prosecutor.nnompleity heorynnhis eact analogy was formalised in an article by eige, hamir and ennenholtz,nnhe oisy racle roblemnn.  very simplified version of their main result is the following ssume we have a contract (judge) who can use  steps to perform a computation (potentially spread over multiple transactions). here are several outside actors (lawyers) who can help the judge and at least one of them is honest (i.e. at least one actor follows a given protocol, the others may be malicious and send arbitrary messages), but the judge does not know who the honest actor is. uch a contract can perform any computation that can be carried out using  memory cells and an arbitrary number of steps without outside help. (he formal version states that a polynomial-time verifier can accept all of  in this model)nnhis might sound a bit clunky, but their proof is actually quite instructive and uses the analogy of  being the class of problems that can be solved by "games". s an eample, let me show you how an thereum contract can play chess with almost no gas costs (eperts may forgive me to use chess which is  complete, but we will use the classic  variant here, so it actually is in ...) laying chess in this contet means that some outside actor proposes a chess position and the contract has to determine whether the position is a winning position for white, i.e. white always wins, assuming white and black are infinitely clever. his assumes that the honest off-chain actor has enough computing power to play chess perfectly, but well... o the task is not to play chess against the outside actors, but to determine whether the given position is a winning position for white and asking the outside actors (all ecept one of which might be misleading by giving wrong answers) for help.  hope you agree that doing this without outside help is etremely complicated. or simplicity, we only look at the case where we have two outside actors  and . ere is what the contract would donnsk  and  whether this is a winning position for white. f both agree, this is the answer (at least one is honest).nnf they disagree, ask the one who answered "yes" (we will call that actor  from now on, and the other one ) for a winning move for white.nnf the move is invalid (for eample because no move is possible), black winsnntherwise, apply the move to the board and ask  for a winning move for black (because  claimed that black can win)nnf the move is invalid (for eample because no move is possible), white winsnntherwise, apply the move to the board, ask  for a winning move for white and continue with .nnhe contract does not really need to have a clue about chess strategies. t just has to be able to verify whether a single move was valid or not. o the costs for the contract are roughlynn*nn(nn+nn)nn, where  is the number of moves (ply, actually),  is the cost for verifying a move and  is the cost for updating the board.nnhis result can actually be improved to something likenn* + nn, because we do not have to verify every single move. e can just update the board (assuming moves are given by coordinates) and while we ask for the net move, we also ask whether the previous move was invalid. f that is answered as "yes", we check the move. epending on whether the move was valid or not, one of the players cheated and we know who wins.nnomework mprove the contract so that we only have to store the sequence of moves and update the board only for a tiny fraction of the moves and perform a move verification only for a single move, i.e. bring the costs to something likenn* + tiny()* + nn, where  is the cost for storing a move and tiny is an appropriate function which returns a "tiny fraction" of .nnn a side note,nnabai, ortnow and undnnshowed that a model where the lawyers are cooperating but cannot communicate with each other and the judge is allowed to roll dice (both changes are important) captures an allegedly much larger class called , nondeterministic eponential time.nndding ryptoeconomics to the amennne thing to remember from the previous section is that, assuming transactions do not get censored, the contract will always find out who the honest and who the dis-honest actor was. his leads to the interesting observation that we now have a rather cheap interactive protocol to solve hard problems, but we can add a cryptoeconomic mechanism that ensures that this protocol almost never has to be carried out he mechanism allows anyone to submit the result of a computation together with a security deposit. nyone can challenge the result, but also has to provide a deposit. f there is at least one challenger, the interactive protocol (or its multi-prover variant) is carried out. ssuming there is at least one honest actor among the set of proposers and challengers, the dishonest actors will be revealed and the honest actor will receive the deposits (minus a percentage, which will disincentivise a dishonest proposer from challenging themselves) as a reward. o the end result is that as long as at least one honest person is watching who does not get censored, there is no way for a malicious actor to succeed, and even trying will be costly for the malicious actor.nnpplications that want to use the computation result can take the deposits as an indicator for the trustworthiness of the computation f there is a large deposit from the solution proposer and no challenge for a certain amount of time, the result is probably correct. s soon as there are challenges, applications should wait for the protocol to be resolved. e could even create a computation result insurance that promises to check computations off-chain and refunds users in case an invalid result was not challenged early enough.nnhe ower of inary earchnnn the net two sections,  will give two specific eamples. ne is about interactively verifying the presence of data in a foreign blockchain, the second is about verifying general (deterministic) computation. n both of them, we will often have the situation where the proposer has a very long list of values (which is not directly available to the contract because of its length) that starts with the correct value but ends with an incorrect value (because the proposer wants to cheat). he contract can easily compute the (i+)st value from the ith, but checking the full list would be too epensive. he challenger knows the correct list and can ask the proposer to provide several values from this list. ince the first value is correct and the last is incorrect, there must be at least one point i in this list where the ith value is correct and the (i+)st value is incorrect, and it is the challenger's task to find this position (let us call this point the "transition point"), because then the contract can check it.nnet us assume the list has a length of .., so we have a search range from  to ... he challenger asks for the value at position .. f it is correct, there is at least one transition point between . and ... f it is incorrect, there is a transition point between  and .. n both cases, the length of the search range was reduced by one half. e now repeat this process until we reach a search range of size , which must be the transition point. he logarithm to the basis two can be used to compute the number of steps such an "iterated bisection" takes. n the case of .., these are log .. ≈  steps.nnheap ross-hain ransfersnns a first real-world eample,  would like to show how to design an etremely cheap cross-chain state or payment verification. ue to the fact that blockchains are not deterministic but can fork, this is a bit more complicated, but the general idea is the same.nnhe proposer submits the data she wants to be available in the target contract (e.g. a bitcoin or dogecoin transaction, a state value in another thereum chain, or anything in a erkle- whose root hash is included in the block header of a blockchain and is publicly known (this is very important)) together with the block number, the hash of that block header and a deposit.nnote that we only submit a single block number and hash. n the first version of elay, currently all bitcoin block headers need to be submitted and the proof of work is verified for all of them. his protocol will only need that information in case of an attack.nnf everything is fine, i.e. eternal verifiers check that the hash of the block number matches the canonical chain (and optionally has some confirmations) and see the transaction / data included in that block, the proposer can request a return of the deposit and the cross-chain transfer is finished. hat's all there is in the non-attack case. his should cost about  gas per transfer.nnf something is wrong, i.e. we either have a malicious proposer / submitter or a malicious challenger, the challenger now has two possibilitiesnndeclare the block hash invalid (because it does not eist or is part of an abandoned fork) ornndeclare the erkle-hashed data invalid (but the block hash and number valid)nnote that a blockchain is a erkle- consisting of two "arms" ne that forms the chain of block headers and one that forms the erkle- of state or transactions. nce we accept the root (the current block header hash) to be valid, verifications in both arms are simple erkle--proofs.nn() o let us consider the second case first, because it is simpler s we want to be as efficient as possible, we do not request a full erkle- proof from the proposer. nstead we just request a path through the  from the root to the data (i.e. a sequence of child indices).nnf the path is too long or has invalid indices, the challenger asks the proposer for the parent and child values at the point that goes out of range and the proposer cannot supply valid data that hashes to the parent. therwise, we have the situation that the root hash is correct but the hash at some point is different. sing binary search we find a point in the path where we have a correct hash directly above an incorrect one. he proposer will be unable to provide child values that hash to the correct hash and thus the fraud is detectable by the contract.nn() et us now consider the situation where the proposer used an invalid block or a block that was part of an abandoned fork. et us assume that we have a mechanism to correlate the block numbers of the other blockchain to the time on the thereum blockchain, so the contract has a way to tell a block number invalid because it must lie in the future. he proposer now has to provide all block headers (only  bytes for bitcoin, if they are too large, start with hashes only) up to a certain checkpoint the contract already knows (or the challenger requests them in chunks). he challenger has to do the same and will hopefully supply a block with a higher block number / total difficulty. oth can now cross-check their blocks. f someone finds an error, they can submit the block number to the contract which can check it or let it be verified by another interactive stage.nnpecific nteractive roofs for eneral omputationsnnssume we have a computing model that respects locality, i.e. it can only make local modifications to the memory in a single step. uring machines respect locality, but random-access-machines (usual computers) are also fine if they only modify a constant number of points in memory in each step. urthermore, assume that we have a secure hash function with  bits of output. f a computation on such a machine needs t steps and uses at most s bytes of memory / state, then we can perform interactive verification (in the proposer/challenger model) of this computation in thereum in about log(t) +  * log(log(s)) +  rounds, where messages in each round are not longer than ma(log(t),  + k + log(s)), where k is the size of the "program counter", registers, tape head position or similar internal state. part from storing messages in storage, the contract needs to perform at most one step of the machine or one evaluation of the hash function.nnroofnnhe idea is to compute (at least on request) a erkle-tree of all the memory that is used by the computation at each single step. he effects of a single step on memory is easy to verify by the contract and since only a constant number of points in memory will be accessed, the consistency of memory can be verified using erkle-proofs.nnithout loss of generality, we assume that only a single point in memory is accessed at each step. he protocol starts by the proposer submitting input and output. he challenger can now request, for various time steps i, the erkle-tree root of the memory, the internal state / program counter and the positions where memory is accessed. he challenger uses that to perform a binary search that leads to a step i where the returned information is correct but it is incorrect in step i + . his needs at most log(t) rounds and messages of size log(t) resp.  + k + log(s).nnhe challenger now requests the value in memory that is accessed (before and after the step) together with all siblings along the path to the root (i.e. a erkle proof). ote that the siblings are identical before and after the step, only the data itself changed. sing this information, the contract can check whether the step is eecuted correctly and the root hash is updated correctly. f the contract verified the erkle proof as valid, the input memory data must be correct (because the hash function is secure and both proposer and challenger have the same pre-root hash). f also the step eecution was verified correct, their output memory data is equal. s the erkle tree siblings are the same, the only way to find a different post-root hash is for the computation or the erkle proof to have an error.nnote that the step described in the previous paragraph took one round and a message size of (+) log(s). o we have log(t) +  rounds and message sizes of ma(log(t), k + (+) log(s)) in total. urthermore, the contract needed to compute the hash function *log(s) times. f s is large or the hash function is complicated, we can decrease the size of the messages a little and reach only a single application of the hash function at the cost of more interactions. he idea is to perform a binary search on the erkle proof as followsnne do not ask the proposer to send the full erkle proof, but only the pre- and post values in memory. he contract can check the eecution of the stop, so let us assume that the transition is correct (including the internal post state and the memory access inde in step i + ). he cases that are left arennthe proposer provided the wrong pre-datannpre- and post-data are correct but the erkle root of the post memory is wrongnnn the first case, the challenger performs an interactive binary search on the path from the erkle tree leaf containing the memory data to the root and finds a position with correct parent but wrong child. his takes at most log(log(s)) rounds and messages of size log(log(s)) resp.  bits. inally, since the hash function is secure, the proposer cannot supply a sibling for the wrong child that hashes to the parent. his can be checked by the contract with a single evaluation of the hash function.nnn the second case, we are in an inverted situation he root is wrong but the leaf is correct. he challenger again performs an interactive binary search in at most log(log(s(n))) rounds with message sizes of log(log(s)) resp.  bits and finds a position in the tree where the parent  is wrong but the child  is correct. he challenger asks the proposer for the sibling  such that (, ) hash to , which the contract can check. ince we know that only the given position in memory could have changed with the eecution of the step,  must also be present at the same position in the erkle-tree of the memory before the step. urthermore, the value the proposer provided for  cannot be correct, since then, (, ) would not hash to  (we know that  is wrong but  and  are correct). o we reduced this to the situation where the proposer supplied an incorrect node in the pre-erkle-tree but a correct root hash. s seen in the first case, this takes at most log(log(s)) rounds and messages of size log(log(s)) resp.  bits to verify.nnverall, we had at most log(t) +  +  * log(log(s)) +  rounds with message sizes at most ma(log(t),  + k + log(s)).nnomework onvert this proof to a working contract that can be used for  or iny (and thus ) programs and integrate it into iper erriam'snnthereum computation marketnn.nnhanks to italik for suggesting to erkle-hash the memory to allow arbitrary intra-step memory sizes! his is by the way most likely not a new result.nnn racticennhese logarithms are nice, but what does that mean in practice et us assume we have a computation that takes  seconds on a  z computer using   of . implifying the relation between real-world clock rate and steps on an artificial architecture, we roughly have t   ≈ nnnnand s   ≈ nnnn. nteractively verifying such a computation should take  +  +  *    rounds, i.e.  *    blocks and use messages of around  bytes (mostly depending on k, i.e. the architecture). f we do not verify the erkle proof interactively, we get  rounds ( blocks) and messages of size  bytes (only the last message is that large).nnf you say that  blocks (roughly  minutes on thereum,  confirmations on bitcoin) sounds like a lot, don't forget what we are talking about here  seconds on a  z machine actually using full   of . f you usually run programs that take so much power, they search for specificnninputnnvalues that satisfy a certain condition (optimizing routines, password cracker, proof of work solver, ...). ince we only want to verify a computation, searching for the values does not need to be performed in that way, we can supply the solution right from the beginning and only check the condition.nnk, right, it should be quite epensive to compute and update the erkle tree for each computation step, but this eample should only show how well this protocol scales on chain. urthermore, most computations, especially in functional languages, can be subdivided into levels where we call an epensive function that use a lot of memory but outputs a small number. e could treat this function as a single step in the main protocol and start a new interactive protocol if an error is detected in that function. inally, as already said n most cases, we simply verify the output and never challenge it (only then do we need to compute the erkle tree), as the proposer will almost certainly lose their deposit.nnpen roblemsnnn several places in this article, we assumed that we only have two eternal actors and at least one of them is honest. e can get close to this assumption by requiring a deposit from both the proposer and the challenger. ne problem is that one of them might just refuse to continue with the protocol, so we need to have timeouts. f we add timeouts, on the other hand, a malicious actor could saturate the blockchain with unrelated transactions in the hope that the answer does not make it into a block in time. s there a possibility for the contract to detect this situation and prolong the timeout urthermore, the honest proposer could be blocked out from the network. ecause of that (and because it is better to have more honest than malicious actors), we might allow the possibility for anyone to step in (on both sides) after having made a deposit. gain, if we allow this, malicious actors could step in for the "honest" side and just pretend to be honest. his all sounds a bit complicated, but  am pretty confident it will work out in the end.