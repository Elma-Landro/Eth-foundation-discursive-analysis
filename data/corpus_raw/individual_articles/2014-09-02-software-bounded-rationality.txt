Titre: Software and Bounded Rationality\nAuteur: Vitalik Buterin\nDate: September 2, 2014\nURL: https://blog.ethereum.org/2014/09/02/software-bounded-rationality\nCatégorie: Non catégorisé\n\n==================================================\n\nne of the key properties that is usually sought for in a cryptoeconomic algorithm, whether a blockchain consensus algorithm such a proof of work or proof of stake, a reputation system or a trading process for something like data transmission or file storage, is the ideal ofnnincentive-compatibilitynn- the idea that it should be in everyone's economic interest to honestly follow the protocol. he key underlying assumption in this goal is the idea that people (or more precisely in this casennnodesnn) are "rational" - that is to say, that people have a relatively simple defined set of objectives and follow the optimal strategy to maimize their achievement of those objectives. n game-theoretic protocol design, this is usually simplified to saying that people like money, since money is the one thing that can be used to help further one's success in almost any objective. n reality, however, this is not precisely the case.nnumans, and even the de-facto human-machine hybrids that are the participants of protocols like itcoin and thereum, are not perfectly rational, and there are specific deviations from rationality that are so prevalent among users that they cannot be simply categorized as "noise". n the social sciences, economics has responded to this concern with the subfield ofnnbehavioral economicsnn, which combines eperimental studies with a set of new theoretical concepts includingnnprospect theorynn,nnbounded rationalitynn, defaults andnnheuristicsnn, and has succeeded in creating a model which in some cases considerably more accurately models human behavior.nnn the contet of cryptographic protocols, rationality-based analyses are arguably similarly suboptimal, and there are particular parallels between some of the concepts for eample, as we will later see, "software" and "heuristic" are essentially synonyms. nother point of interest is the fact that we arguably do not even have an accurate model of what constitutes an "agent", an insight that has particular importance to protocols that try to be "trust-free" or have "no single point of failure".nnraditional modelsnnn traditional fault-tolerance theory, there are three kinds of models that are used for determining how well a decentralized system can survive parts of it deviating from the protocol, whether due to malice or simple failure. he first of these isnnsimple fault tolerancenn. n a simple fault tolerant system, the idea is that all parts of the system can be trusted to do either one of two things eactly follow the protocol, or fail. he system should be designed to detect failures and recover and route around them in some fashion. imple fault tolerance is usually the best model for evaluating systems that are politically centralized, but architecturally decentralized for eample, mazon or oogle's cloud hosting. he system should definitely be able to handle one server going offline, but the designers do not need to think about one of the servers becoming evil (if that does happen, then an outage is acceptable until the mazon or oogle team manually figure out what is going on and shut that server down).nnowever, simple fault tolerance is not useful for describing systems that are not just architecturally, but also politically, decentralized. hat if we have a system where we want to be fault-tolerant against some parts of the system misacting, but the parts of the system might be managed by different organizations or individuals, and you do not trust all of them not to be malicious (although younndonntrust that at least, say, two thirds of them will act honestly) n this case, the model we want isnnyzantine fault tolerancenn(named after thennyzantine enerals roblemnn) - most nodes will honestly follow the protocol, but some will deviate, and they can deviate in any way the assumption is that all deviating nodes are colluding to screw you over.  yzantine-fault-tolerant protocol should survive against a limited number of such deviations.nnor an eample of simple and yzantine fault-tolerance in action, a good use case isnndecentralized file storagenn.nneyond these two scenarios, there is also another even more sophisticated model thennyzantine/ltruistic/ational modelnn. he  model improves upon the yzantine model by adding a simple realization in real life, there is no sharp distinction between "honest" and "dishonest" people everyone is motivated by incentives, and if the incentives are high enough then even the majority of participants may well act dishonestly - particularly if the protocol in question weights people's influence by economic power, as pretty much all protocols do in the blockchain space. hus, the  model assumes three types of actorsnnltruisticnn- altruistic actors always follow the protocolnnationalnn- rational actors follow the protocol if it suits them, and do not follow the protocol if it does notnnyzantinenn- yzantine actors are all conspiring to screw you overnnn practice, protocol developers tend to be uncomfortable assuming any specific nonzero quantity of altruism, so the model that many protocols are judged by is the even harsher "" model protocols that survive under  are said to bennincentive-compatiblenn(anything that survives under  survives under , since an altruist is guaranteed to be at least as good for the health of the protocol as anyone else as benefitting the protocol is their eplicit objective).nnote that these arennworst-case scenariosnnthat the system must survive, not accurate descriptions of reality at all timesnno see how this model works, let us eamine an argument for why itcoin is incentive-compatible. he part of itcoin that we care most about is the mining protocol, with miners being the users. he "correct" strategy defined in the protocol is to always mine on the block with the highest "score", where score is roughly defined as followsnnf a block is the genesis block,nnscore()  nnf a block is invalid,nnscore()  -infinitynntherwise,nnscore()  score(.parent) + nnn practice, the contribution that each block makes to the total score varies with difficulty, but we can ignore such subtleties in our simple analysis. f a block is successfully mined, then the miner receives a reward of  . n this case, we can see that there are eactly three yzantine strategiesnnot mining at allnnining on a block other than the block with highest scorennrying to produce an invalid blocknnhe argument against () is simple if you don't mine, you don't get the reward. ow, let's look at () and (). f you follow the correct strategy, you have a probabilitynnpnnof producing a valid block with scorenns + nnfor somennsnn. f you follow a yzantine strategy, you have a probabilitynnpnnof producing a valid block with scorennq + nnwithnnq  snn(and if you try to produce an invalid block, you have a probability of producing some block with score negative infinity). hus, your block is not going to be the block with the highest score, so other miners are not going to mine on it, so your mining reward will not be part of the eventual longest chain. ote that this argument does not depend on altruism it only depends on the idea that you have an incentive to keep in line if everyone else does - a classicnnchelling pointnnargument.nnhe best strategy to maimize the chance that your block will get included in the eventual winning blockchain is to mine on the block that has the highest score.nnrust-ree ystemsnnnother important category of cryptoeconomic protocols is the set of so-called "trust-free" centralized protocols. f these, there are a few major categoriesnnrovably fair gamblingnnne of the big problems in online lotteries and gambling sites is the possibility of operator fraud, where the operator of the site would slightly and imperceptibly "load the dice" in their favor.  major benefit of cryptocurrency is its ability to remove this problem by constructing a gambling protocol that is auditable, so any such deviation can be very quickly detected.  rough outline of a provably fair gambling protocol is as followsnnt the beginning of each day, the site generates a seednnsnnand publishesnn(s)nnwherennnnis some standard hash function (eg. )nnhen a user sends a transaction to make a bet, the "dice roll" is calculated usingnn(s + ) mod nnnwherennnnis the transaction used to pay for the bet andnnnnnis the number of possible outcomes (eg. if it's a -sided die,nnn  nn, for a lottery with a  in  chance of winning,nnn  nnand winning games are games wherenn(s + ) mod   nn).nnt the end of the day, the site publishesnnsnn.nnsers can then verify that () the hash provided at the beginning of the day actually isnn(s)nn, and () that the results of the bets actually match the formulas. hus, a gambling site following this protocol has no way of cheating without getting caught within  hours as soon as it generatesnnsnnand needs to publish a valuenn(s)nnit is basically bound to follow the precise protocol correctly.nnroof of olvencynnnother application of cryptography is the concept of creating auditable financial services (technically, gambling is a financial service, but here we are interested in services thatnnholdnnyour money, not just briefly manipulate it). here arennstrong theoretical arguments and empirical evidencennthat financial services of that sort are much more likely to try to cheat their users perhaps the most parcticularly jarring eample is thenncase of tonn, a itcoin echange which shut down with over ,  of customer funds missing.nnhe idea behind proof of solvency is as follows. uppose there is an echange with usersnn] ... n]nnwhere usernni]nnhas balancennbi]nn. he sum of all balances isnnnn. he echange wants to prove that it actually has the bitcoins to cover everyone's balances. his is a two-part problem the echange must simultaneously prove that for somennnnit is true that () the sum of users' balances isnnnn, and (ii) the echange is in possession of at leastnnnn. he second is easy to prove just sign a message with the private key that holds the bitcoins at the time. he simplest way to prove the first is to just publish everyone's balances, and let people check that their balances match the public values, but this compromises privacy hence, a better strategy is needed.nnhe solution involves,nnas usualnn, a erkle tree - ecept in this case it's a funky enhanced sort of erkle tree called a "erkle sum tree". nstead of each node simply being the hash of its children, every node contains the hash of its children and the sum of the values of its childrennnhe values at the bottom are mappings of account s to balances. he service publishes the root of the tree, and if a user wants a proof that their account is correctly included in the tree, the service can simply give them the branch of the tree corresponding to their accountnnhere are two ways that the site can cheat, and try to get away with having a fractional reserve. irst, it can try to have one of the nodes in the erkle tree incorrectly sum the values of its children. n this case, as soon as a user requests a branch containing that node they will know that something is wrong. econd, it can try to insert negative values into the leaves of the tree. owever, if it does this, then unless the site provides fake positive and negative nodes that cancel each other out (thus defeating the whole point), then there will be at least one legitimate user whose erkle branch will contain the negative value in general, getting away with having  percent less than the required reserve requires counting on a specific  percent of users never performing the audit procedure - a result that is actually the best that any protocol can do, given that an echange can always simply zero out some percentage of its users' account balances if it knows that they will never discover the fraud.nnultisignn third application, and a very important one, isnnmultisignn, or more generally the concept of multi-key authorization. nstead of your account being controlled by one private key which may get hacked, there are three keys, of which two are needed to access the account (or some other configuration, perhaps involving withdrawal limits or time-locked withdrawals itcoin does not support such features but more advanced systems do). he way multisig is usually implemented so far is as a -of- you have one key, the server has one key, and you have a third backup key in a safe place. n the course of normal activity, when you sign a transaction you generally sign it with your key locally, then send it to the server. he server performs some second verification process - perhaps consisting of sending a confirmation code to your phone, and if it confirms that you meant to send the transaction then it signs it as well.nnhe idea is that such a system is tolerant against any single fault, including any single yzantine fault. f you lose your password, you have a backup, which together with the server can recover your funds, and if your password is hacked, the attacker only has one password likewise for loss or theft of the backup. f the service disappears, you have two keys. f the service is hacked or turns out to be evil, it only has one. he probability of two failures happening at the same time is very small arguably, you are more likely to die.nnundamental nitsnnll of the above arguments make one key assumption that seems trivial, but actually needs to be challenged much more closely that the fundamental unit of the system is the computer. achnnnodennhas the incentive to mine on the block with the highest score and not follow some deviant strategy. f thennservernngets hacked in a multisig then yournncomputernnand your backup still have  out of  keys, so you are still safe. he problem with the approach is that it implicitly assumes that users have full control over their computers, and that the users fully understand cryptography and are manually verifying the erkle tree branches. n reality, this is not the case in fact, the very necessity of multisig in any incarnation at all is proof of this, as it acknowledges that users' computers can get hacked - a replica of the behavioral-economics idea that individuals can be viewed as not being in full control of themselves.nn more accurate model is to view a node as a combination of two categories of agents a user, and one or more software providers. sers in nearly all cases do not verify their software even in my own case, even though  verify every transaction that comes out of the thereum eodus address, using thennpybitcointoolsnntoolkit that  wrote from scratch myself (others have provided patches, but even those  reviewed personally),  am still trusting that () the implementations of ython and buntu that  downloaded are legitimate, and () that the hardware is not somehow bugged. ence, these software providers should be treated as separate entities, and their goals and incentives should be analyzed as actors in their own right. eanwhile, users should also be viewed as agents, but as agents who have limited technical capability, and whose choice set often simply consists of which software packages to install, and not precisely which protocol rules to follow.nnhe first, and most important, observation is that the concepts of "yzantine fault tolerance" and "single point of failure" should be viewed in light of such a distinction. n theory, multisig removes all single points of failure from the cryptographic token management process. n practice, however, that is not the way that multisig is usually presented. ight now, most mainstream multisig wallets are web applications, and the entity providing the web application is the same entity that manages the backup signing key. hat this means is that, if the wallet provider does get hacked or does turn out to be evil, they actually have control over two out of three keys - they already have the first one, and can easily grab the second one simply by making a small change to the client-side browser application they send to you every time you load the webpage.nnn multisig wallet providers' defense, services like ito and reenddress do offer an , allowing developers to use their key management functionality without their interface so that the two providers can be separate entities. owever, the importance of this kind of separation is currently drastically underemphasized.nnhis insight applies equally well to provably fair gambling and proof of solvency. articular, such provably fair protocols should have standard implementations, with open-source applications that can verify proofs in a standard format and in a way that is easy to use. ervices like echanges should then follow those protocols, and deliver proofs which can be verifies by these eternal tools. f a service releases a proof that can only be verified by its own internal tools, that is not much better than no proof at all - slightly better, since there is a chance that cheating will still be detected, but not by much.nnoftware, sers and rotocolsnnf we actually do have two classes of entities, it will be helpful to provide at least a rough model of their incentives, so that we may better understand how they are likely to act. n general, from software providers we can roughly epect the following goalsnnaimize profitnn- in the heyday of proprietary software licensing, this goal was actually easy to understand software companies maimize their profits by having as many users as possible. he drive toward open-source and free-to-use software more recently has very many advantages, but one disadvantage is that it now makes the profit-maimization analysis much more difficult. ow, software companies generally make money through commercial value-adds, the defensibility of which typically involves creating proprietary walled-garden ecosystems. ven still, however, making one's software as useful as possible usually helps, at least when it doesn't interfere with a proprietary value-add.nnltruismnn- altruists write software to help people, or to help realize some vision of the world.nnaimize reputationnn- these days, writing open-source software is often used as a way of building up one's resume, so as to () appear more attractive to employers and () gain the social connections to maimize potential future opportunities. orporations can also do this, writing free tools to drive people to their website in order to promote other tools.nnazinessnn- software providers will not write code if they can help it. he main consequence of this will be an underinvestment in features that do not benefit their users, but benefit the ecosystem - like responding to requests for data - unless the software ecosystem is an oligopoly.nnot going to jailnn- this entails compliance with laws, which sometimes involves anti-features such as requiring identity verification, but the dominant effect of this motive is a disincentive against screwing one's customers over too blatantly (eg. stealing their funds).nnsers we will not analyze in terms of goals but rather in terms of a behavioral model users select software packages from an available set, download the software, and choose options from inside that software. uiding factors in software selection includennunctionalitynn- what is the utility (that's the economics jargon "utility") can they derive from the options that the software providesnnase of usenn- of particular importance is the question of how quickly they can get up and running doing what they need to do.nnerceived legitimacynn- users are more likely to download software from trustworthy or at least trustworthy-seeming entities.nnaliencenn- if a software package is mentioned more often, users will be more likely to go for it. n immediate consequence is that the "official" version of a software package has a large advantage over any forks.nnoral and ideological considerationsnn- users might prefer open source software for its own sake, reject purely parasitic forks, etc.nnnce users download a piece of software, the main bias that we can count on is that users will stick to defaults even when it might not benefit them to beyond that, we have more traditional biases such as loss aversion, which we will discuss briefly later.nnow, let us show an eample of how this process works in action itorrent. n the itorrent protocol, users can download files from each other a packet at a time in a decentralized fashion, but in order for one user to download a file there must be someone uploading ("seeding") it - and that activity is not incentivized. n fact, it carries non-negligible costs bandwidth consumption,  resource consumption, copyright-related legal risk (including risk of getting one's internet connection shut down by one's , or perhaps even a possibility of lawsuit). nd yet people still seed - vastly insufficiently, but they do.nnhy he situation is eplained perfectly by the two-layer model software providers want to make their software more useful, so they include the seeding functionality by default, and users are too lazy to turn it off (and some users are deliberately altruistic, though the order-of-magnitude mismatch between willingness to torrent copyrighted content and willingness to donate to artists does suggest that most participants don't really care). essage-sending in itcoin (ie. to data requests likenngetblockheadernnandnngetrawtransactionnn) is also altruistic but also similarly eplainable, as is the inconsistency between transaction fees and what the economics suggest transaction fees currently should be.nnnother eample is proof of stake algorithms. roof of stake algorithms have the (mostly) common vulnerability that there is "nothing at stake" - that is to say, that the default behavior in the event of a fork is to try to vote on all chains, so an attacker need only overpower all altruists that vote on one chain only, and not all altruists plus all rational actors as in the case of proof of work. ere, once again we can see that this does not mean that proof of stake is completely broken. f the stake is largely controlled by a smaller number of sophisticated parties, then those parties will have their ownership in the currency as the incentive not to participate in forks, and if the stake is controlled by very many more ordinary people then there would need to be some deliberately evil software provider who would take an effort to include a multi-voting feature, and advertise it so that potentially users actually know about the feature.nnowever, if the stake is held in custodial wallets (eg. oinbase, apo, etc) which do not legally own the coins, but are specialized professional entities, then this argument breaks down they have the technical ability to multi-vote, and low incentive not to, particularly if their businesses are not "itcoin-centric" (or thereum-centric, or ipple-cetric) and support many protocols. here is even a probabilistic multi-voting strategy which such custodial entities can use to get % of the benefits of multi-voting without the risk of getting caught. ence, effective proof of stake to a moderate etent depends on technologies that allow users to safely keep control of their own coins.nnarker onsequencesnnhat we get out of the default effect is essentially a certain level of centralization, having a beneficial role by setting users' default behavior toward a socially beneficial action and thereby correcting for what would otherwise be a market failure. ow, if software introduces some benefits of centralization, we can also epect some of the negative effects of centralization as well. ne particular eample is fragility. heoretically, itcoin mining is an -of- protocol where  is in the thousands if you do the combinatoric math, the probability that even % of the nodes will deviate from the protocol is infinitesimally small, so itcoin should have pretty much perfect reliability. n reality, of course, this is incorrect itcoin has had no less than two outages in the last si years.nnor those who do not remember, the two cases were as followsnnriver of -year-old car eploits integer overflow vulnerability, sells it for % of original purchase price passing it off as newnnn , an unknown user created a transaction with two outputs, each containing slightly more than nnnnsatoshis. he two outputs combined were slightly over nnnn, and integer overflow led to the total wrapping around to near-zero, causing the itcoin client to think that the transaction actually released only the same small quantity of  that it consumed as an input, and so was legitimate. he bug was fied, and the blockchain reverted, after nine hours.nnn , a new version of the itcoin client unknowingly fied a bug in which a block that made over  accesses to a certain database resource would cause a erkeley error, leading to the client rejecting the block. uch a block soon appeared, and new clients accepted it and old clients rejected it, leading to a fork. he fork was fied in si hours, but in the meantime $ of  was stolen from a payment service provider in a double-spend attack.nnn both cases, the network was only able to fail because, even though there were thousands of nodes, there was only one software implementation running them all - perhaps the ultimate fragility in a network that is often touted for being antifragile. lternative implementations such as btcd are now increasingly being used, but it will be years before itcoin ore's monopoly is anything close to broken and even then fragility will still be fairly high.nnndowment effects and efaultsnnn important set of biases to keep in mind on the user side are the concepts of the endowment effect, loss aversion, and the default effect. he three often go hand in hand, but are somewhat different from each other. he default effect is generally most accurately modeled as a tendency to continue following one's current strategy unless there is annsubstantialnnbenefit to switching - in essence, an artificial psychological switching cost ofnnsome value εnn. he endowment effect is the tendency to see things as being more valuable if one already has them, and loss aversion is the tendency to care more about avoiding losses than seeking gains - eperimentally, the scaling factor seems to be consistently around .nnhe consequences of these effects pronounce themselves most strongly in the contet of multi-currency environments. s one eample, consider the case of employees being paid in . e can see that when people are paid in , they are much more likely to hold on to those  than they would have been likely to buy the  had they been paid  the reason is partially the default effect, and partially the fact that if someone is paid in  they "think in " so if they sell to  then if the value of  goes up after that they have a risk of suffering a loss, whereas if someone is paid in  it is the -value of their  that they are more concerned with. his applies also to smaller token systems if you pay someone in etacoin, they are likely to cash out into  or some other coin, but the probability is much less than %.nnhe loss aversion and default effects are some of the strongest arguments in favor of the thesis that a highly polycentric currency system is likely to continue to survive, contra aniel rawisz's viewpoint thatnn is the one token to rule them allnn. here is clearly an incentive for software developers to create their own coin even if the protocol could work just as well on top of an eisting currency you can do a token sale. tor is the latest eample of this. owever, asnnaniel rawisz arguesnn, one could simply fork such an "app-coin" and release a version on top of itcoin, which would theoretically be superior because itcoin is a more liquid asset to store one's funds in. he reason why such an outcome has a large chance of not happening is simply the fact that users follow defaults, and by default users will use tor with torcoin since that is what the client will promote, and the original tor client and website and ecosystem is the one that will get all the attention.nnow, this argument breaks down somewhat in one case if the fork is itself backed by a powerful entity. he latest eample of this is the case of ipple and tellar although tellar is a fork of ipple, it is backed by a large company, tripe, so the fact that the original version of a software package has the advantage of much greater salience does not apply quite as strongly. n such cases, we do not really know what will happen perhaps, as is often the case in the social sciences, we will simply have to wait for empirical evidence to find out.nnhe ay orwardnnelying on specific psychological features of humans in cryptographic protocol design is a dangerous game. he reason why it is good in economics to keep one's model simple, and in cryptoeconomics even more so, is that even if desires like the desire to acquire more currency units do not accurately describe the whole of human motivation, they describe an evidently very powerful component of it, and some may argue the only powerful component we can count on. n the future, education may begin to deliberately attack what we know as psychological irregularities (in fact, it already does), changing culture may lead to changing morals and ideals, and particularly in this case the agents we are dealing with are "nnfyborgsnn" - functional cyborgs, or humans who have all of their actions mediated by machines like the one that sits between them and the internet.nnowever, there are certain fundamental features of this model - the concept of cryptoeconomic systems as two-layer systems featuring software and users as agents, the preference for simplicity, etc, that perhaps can be counted on, and at the very least we should try to be aware of circumstances where our protocol is secure under the  model, but insecure under the model where a few centralized parties are in practice mediating everyone's access to the system. he model also highlights the importance of "software politics" - having an understanding of the pressures that drive software development, and attempting to come up with approaches to development that software developers have the best possible incentives (or, ultimately, write software that is most favorable to the protocol's successful eecution). hese are problems that itcoin has not solved, and that thereum has not solved perhaps some future system will do at least somewhat better.