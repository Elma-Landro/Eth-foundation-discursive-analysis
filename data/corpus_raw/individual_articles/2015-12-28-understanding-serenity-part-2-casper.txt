Titre: Understanding Serenity, Part 2: Casper\nAuteur: Vitalik Buterin\nDate: December 28, 2015\nURL: https://blog.ethereum.org/2015/12/28/understanding-serenity-part-2-casper\nCatégorie: Non catégorisé\n\n==================================================\n\npecial thanks to lad amfir for introducing the idea of by-block consensus and convincing me of its merits, alongside many of the other core ideas of asper, and to lad amfir and reg eredith for their continued work on the protocolnnn the last post in this series, we discussed one of the two flagship feature sets of erenity a heightened degree of abstraction that greatly increases the fleibility of the platform and takes a large step in moving thereum from "itcoin plus uring-complete" to "general-purpose decentralized computation". ow, let us turn our attention to the other flagship feature, and the one for which the erenity milestone was originally created the asper proof of stake algorithm.nnonsensus y etnnhe keystone mechanism of asper is the introduction of a fundamentally new philosophy in the field of public economic consensus the concept ofnnconsensus-by-betnn. he core idea of consensus-by-bet is simple the protocol offers opportunities for validators to betnnagainst the protocolnnon which blocks are going to be finalized.  bet on some block  in this contet is a transaction which, by protocol rules, gives the validator a reward of  coins (which are simply printed to give to the validator out of thin air, hence "against the protocol")nnin all universes in which block  was processednnbut which gives the validator a penalty of  coins (which are destroyed) in all universes in which block  was not processed.nnhe validator will wish to make such a bet only if they believe block  is likely enough to be processed innnthe universe that people care aboutnnthat the tradeoff is worth it. nd then, here's the economically recursive fun part the universe that people care about, ie. the state that users' clients show when users want to know their account balance, the status of their contracts, etc,nnis itself derived by looking at which blocks people bet on the mostnn. ence, each validator's incentive is to bet in the way that they epect others to bet in the future, driving the process toward convergence.nn helpful analogy here is to look at proof of work consensus - a protocol which seems highly unique when viewed by itself, but which can in fact be perfectly modeled as a very specific subset of consensus-by-bet. he argument is as follows. hen you are mining on top of a block, you are epending electricity costsnnnnper second in echange for receiving a chancennpnnper second of generating a block and receivingnnnncoinsnnin all forks containing your blocknn, and zero rewards in all other chainsnnence, every second, you receive an epected gain ofnnp*-nnon the chain you are mining on, and take a loss ofnnnnon all other chains this can be interpreted as taking a bet atnnp*-nnodds that the chain you are mining on will "win" for eample, if p is  in  million,  is   ~ $  and  is $., then your gains per second on the winning chain arenn. *  - .  .nn, your losses on the losing chain are the electricity cost ofnn.nn, and so you are betting at  odds (or % probability) that the chain you are mining on will win. ote that proof of work satisfies the requirement of being economically "recursive" in the way described above users' clients will calculate their balances by processing the chain that has the most proof of work (ie. bets) behind it.nnonsensus-by-bet can be seen as a framework that encompasses this way of looking at proof of work, and yet also can be adapted to provide an economic game to incentivize convergence for many other classes of consensus protocols. raditionalnnyzantine-fault-tolerantnnconsensus protocols, for eample, tend to have a concept of "pre-votes" and "pre-commits" before the final "commit" to a particular result in a consensus-by-bet model, one can make each stage be a bet, so that participants in the later stages will have greater assurance that participants in the earlier stages "really mean it".nnt can also be used to incentivize correct behavior in out-of-band human consensus, if that is needed to overcome etreme circumstances such as a % attack. f someone buys up half the coins on a proof-of-stake chains, and attacks it, then the community simply needs to coordinate on a patch where clients ignore the attacker's fork, and the attacker and anyone who plays along with the attacker automatically loses all of their coins.  very ambitious goal would be to generate these forking decisions automatically by online nodes - if done successfully, this would also subsume into the consensus-by-bet framework the underappreciated but important result from traditional fault tolerance research that, under strong synchrony assumptions, even if almost all nodes are trying to attack the system the remaining nodesnncan still come to consensusnn.nnn the contet of consensus-by-bet, different consensus protocols differ in only one way who is allowed to bet, at what odds and how much n proof of work, there is only one kind of bet offered the ability to bet on the chain containing one's own block at oddsnnp*-nn. n generalized consensus-by-bet, we can use a mechanism known as annscoring rulennto essentially offer an infinite number of betting opportunities one infinitesimally small bet at , one infinitesimally small bet at ., one infinitesimally small bet at ., and so forth.nn scoring rule as an infinite number of bets.nnne can still decide eactly how large these infinitesimal marginal bets are at each probability level, but in general this technique allows us to elicit a very precise reading of the probability with which some validator thinks some block is likely to be confirmed if a validator thinks that a block will be confirmed with probability %, then they will accept all of the bets below  odds and none of the bets above  odds, and seeing this the protocol will be able to infer this "opinion" that the chance the block will be confirmed is % with eactness. n fact, thennrevelation principlenntells us that we may as well ask the validators to supply a signed message containing their "opinion" on the probability that the block will be confirmed directly, and let the protocol calculate the bets on the validator's behalf.nnhanks to the wonders of calculus, we can actually come up with fairly simple functions to compute a total reward and penalty at each probability level that are mathematically equivalent to summing an infinite set of bets at all probability levels below the validator's stated confidence.  fairly simple eample isnns(p)  p/(-p)nnandnnf(p)  (p/(-p))^/nnwherennsnncomputes your reward if the event you are betting on takes place andnnfnncomputes your penalty if it does not.nn key advantage of the generalized approach to consensus-by-bet is this. n proof of work, the amount of "economic weight" behind a given block increases only linearly with time if a block has si confirmations, then reverting it only costs miners (in equilibrium) roughly si times the block reward, and if a block has si hundred confirmations then reverting it costs si hundred times the block reward. n generalized consensus-by-bet, the amount of economic weight that validators throw behind a block could increase eponentially if most of the other validators are willing to bet at , you might be comfortable sticking your neck out at , and once almost everyone bets  you might go for  or even higher. ence, a block may well reach a level of "de-facto complete finality", where validators' entire deposits are at stake backing that block, in as little as a few minutes, depending on how brave the validators are (and how much the protocol incentivizes them to be).nn-foot view summary the blockchain is a prediction market on itself.nnlocks, hains and onsensus as ug of arnnnother unique component of the way that asper does things is that rather than consensus beingnnby-chainnnas is the case with current proof of work protocols, consensus isnnby-blocknn the consensus process comes to a decision on the status of the block at each height independently of every other height. his mechanism does introduce some inefficiencies - particularly, a bet must register the validator's opinion on the block at every height rather than just the head of the chain - but it proves to be much simpler to implement strategies for consensus-by-bet in this model, and it also has the advantage that it is much more friendly to high blockchain speed theoretically, one can even have a block time that is faster than network propagation with this model, as blocks can be produced independently of each other, though with the obvious proviso that blocknnfinalizationnnwill still take a while longer.nnn by-chain consensus, one can view the consensus process as being a kind of tug-of-war between negative infinity and positive infinitynnat each forknn, where the "status" at the fork represents the number of blocks in the longest chain on the right side minus the number of blocks on the left sidennlients trying to determine the "correct chain" simply move forward starting from the genesis block, and at each fork go left if the status is negative and right if the status is positive. he economic incentives here are also clear once the status goes positive, there is a strong economic pressure for it to converge to positive infinity, albeit very slowly. f the status goes negative, there is a strong economic pressure for it to converge to negative infinity.nnncidentally, note that under this framework the core idea behind thenn scoring rulennbecomes a natural generalization - instead of just counting the length of the longest chain toward the status, count every block on each side of the forknnn by-block consensus, there is once again the tug of war, though this time the "status" is simply an arbitrary number that can be increased or decreased by certain actions connected to the protocol at every block height, clients process the block if the status is positive and do not process the block if the status is negative. ote that even though proof of work is currently by-chain, it doesn't have to be one can easily imagine a protocol where instead of providing a parent block, a block with a valid proof of work solution must provide a + or - vote on every block height in its history + votes would be rewarded only if the block that was voted on does get processed, and - votes would be rewarded only if the block that was voted on does not get processednnf course, in proof of work such a design would not work well for one simple reason if you have to vote on absolutelynneverynnprevious height, then the amount of voting that needs to be done will increase quadratically with time and fairly quickly grind the system to a halt. ith consensus-by-bet, however, because the tug of war can converge to complete finality eponentially, the voting overhead is much more tolerable.nnne counterintuitive consequence of this mechanism is the fact that a block can remain unconfirmed even when blocks after that block are completely finalized. his may seem like a large hit in efficiency, as if there is one block whose status is flip-flopping with ten blocks on top of it then each flip would entail recalculating state transitions for an entire ten blocks, but note that in a by-chain model the eact same thing can happen between chains as well, and the by-block version actually provides users withnnmorenninformation ifnntheirnntransaction was confirmed and finalized in block , and they know thatnnregardless ofnnthe contents of block  that transaction will have a certain result, thennnthe result that they care aboutnnis finalized even though parts of the history before the result are not. y-chain consensus algorithms can never provide this property.nno how does asper work anywaynnn any security-deposit-based proof of stake protocol, there is a current set of bonded validators, which is kept track of as part of the state in order to make a bet or take one of a number of critical actions in the protocol, you must be in the set so that you can be punished if you misbehave. oining the set of bonded validators and leaving the set of bonded validators are both special transaction types, and critical actions in the protocol such as bets are also transaction types bets may be transmitted as independent objects through the network, but they can also be included into blocks.nnn keeping with erenity's spirit of abstraction, all of this is implemented via annasper contractnn, which has functions for making bets, joining, withdrawing, and accessing consensus information, and so one can submit bets and take other actions simply by calling the asper contract with the desired data. he state of the asper contract looks as followsnnhe contract keeps track of the current set of validators, and for each validator it keeps track of si primary thingsnnhe return address for the validator's depositnnhe current size of the validator's deposit (note that the bets that the validator makes will increase or decrease this value)nnhe validator'snnvalidation codennhe sequence number of the most recent betnnhe hash of the most recent betnnhe validator'snnopinionnntablennhe concept of "validation code" is another abstraction feature in erenity whereas other proof of stake protocols require validators to use one specific signature verification algorithm, the asper implementation in erenity allows validators to specify a piece of code that accepts a hash and a signature and returns  or , and before accepting a bet checks the hash of the bet against its signature. he default validation code is an  verifier, but one can also eperiment with other verifiers multisig, threshold signatures (potentially useful for creating decentralized stake pools!), amport signatures, etc.nnvery bet must contain a sequence number one higher than the previous bet, and every bet must contain a hash of the previous bet hence, one can view the series of bets made by a validator as being a kind of "private blockchain" viewed in that contet, the validator's opinion is essentially the state of that chain. n opinion is a table that describesnnhat the validator thinks the most likely state root is at any given block heightnnhat the validator thinks the most likely block hash is at any given block height (or zero if no block hash is present)nnow likely the block with that hash is to be finalizednn bet is an object that looks like thisnnhe key information is the followingnnhe sequence number of the betnnhe hash of the previous betnn signaturenn list of updates to the opinionnnhe function in the asper contract that processes a bet has three parts to it. irst, it validates the sequence number, previous hash and signature of a bet. et, it updates the opinion table with any new information supplied by the bet.  bet should generally update a few very recent probabilities, block hashes and state roots, so most of the table will generally be unchanged. inally, it applies the scoring rule to the opinion if the opinion says that you believe that a given block has a % chance of finalization, and if, in the particular universe that this particular contract is running in, the block was finalized, then you might get  points otherwise you might lose  points.nnote that, because the process of running this function inside the asper contract takes place as part of the state transition function,nnthis process is fully aware of what every previous block and state root isnnat least within the contet of its own universe even if, from the point of view of the outside world, the validators proposing and voting on block  have no idea whether or not block  will be finalized, when the validators come around tonnprocessingnnthat block they will be - or, perhaps, they might process both universes and only later decide to stick with one. n order to prevent validators from providing different bets to different universes, we have a simple slashing condition if you make two bets with the same sequence number, or even if you make a bet that you cannot get the asper contract to process, you lose your entire deposit.nnithdrawing from the validator pool takes two steps. irst, one must submit a bet whose maimum height is - this automatically ends the chain of bets and starts a four-month countdown timer ( blocks /  seconds on the testnet) before the bettor can recover their funds by calling a third method,nnwithdrawnn. ithdrawing can be done by anyone, and sends funds back to the same address that sent the originalnnjoinnntransaction.nnlock propositionnn block contains (i) a number representing the block height, (ii) the proposer address, (iii) a transaction root hash and (iv) a signature. or a block to be valid, the proposer address must be the same as the validator that is scheduled to generate a block for the given height, and the signature must validate when run against the validator's own validation code. he time to submit a block at height  is determined bynn   +  * nnwherennnnis the genesis timestamp hence, a block should ordinarily appear every five seconds.nnn -style random number generator is used to determine who can generate a block at each height essentially, this involves takingnnmissing block proposersnnas a source of entropy. he reasoning behind this is that even though this entropy is manipulable, manipulation comes at a high cost one must sacrifice one's right to create a block and collect transaction fees in order to manipulate it. f it is deemed absolutely necessary, the cost of manipulation can be increased several orders of magnitude further by replacing the -style  with annnn-like protocol.nnhe alidator trategynno how does a validator operate under the asper protocol alidators have two primary categories of activity making blocks and making bets. aking blocks is a process that takes place independently from everything else validators gather transactions, and when it comes time for them to make a block, they produce one, sign it and send it out to the network. he process for making bets is more complicated. he current default validator strategy in asper is one that is designed to mimic aspects of traditional yzantine-fault-tolerant consensus look at how other validators are betting, take the rd percentile, and move a step toward  or  from there.nno accomplish this, each validator collects and tries to stay as up-to-date as possible on the bets being made by all other validators, and keeps track of the current opinion of each one. f there are no or few opinions on a particular block height from other validators, then it follows an initial algorithm that looks roughly as followsnnf the block is not yet present, but the current time is still very close to the time that the block should have been published, bet .nnf the block is not yet present, but a long time has already passed since the block should have been published, bet .nnf the block is present, and it arrived on time, bet .nnf the block is present, but it arrived either far too early or far too late, bet .nnome randomness is added in order to help prevent "stuck" scenarios, but the basic principle remains the same.nnf there are already many opinions on a particular block height from other validators, then we take the following strategynnetnnnnbe the value such that two thirds of validators are betting higher thannnnn. etnnnnbe the median (ie. the value such that half of validators are betting higher thannnnn). etnnnnbe the value such that two thirds of validators are betting lower thannnnn.nnetnne()nnbe a function that makesnnnnmore "etreme", ie. pushes the value away from . and toward .  simple eample is the piecewise functionnne()  . +  /  if   . else  / nn.nnfnn  .nn, betnne()nnfnn  .nn, betnne()nntherwise, betnne()nn, though limit the result to be within the rangenn., .]nnso that less than % of validators can't force another validator to move their bets too farnnalidators are free to choose their own level of risk aversion within the contet of this strategy by choosing the shape ofnnenn.  function wherennf(e)  .nnfornne  .nncould work (and would in fact likely provide the same behavior as endermint) but it creates somewhat higher risks and allows hostile validators making up a large portion of the bonded validator set to trick these validators into losing their entire deposit at a low cost (the attack strategy would be to bet ., trick the other validators into betting ., and then jump back to betting . and force the system to converge to zero). n the other hand, a function that converges very slowly will incur higher inefficiencies when the system is not under attack, as finality will come more slowly and validators will need to keep betting on each height longer.nnow, how does annclientnndetermine what the current state is ssentially, the process is as follows. t starts off by downloading all blocks and all bets. t then uses the same algorithm as above to construct its own opinion, but it does not publish it. nstead, it simply looks at each height sequentially, processing a block if its probability is greater than . and skipping it otherwise the state after processing all of these blocks is shown as the "current state" of the blockchain. he client can also provide a subjective notion of "finality" when the opinion at every height up to somennknnis either above .% or below .%, then the client considers the firstnnknnblocks finalized.nnurther esearchnnhere is still quite a bit of research to do for asper and generalized consensus-by-bet. articular points includennoming up with results to show that the system economically incentivizes convergence, even in the presence of some quantity of yzantine validatorsnnetermining optimal validator strategiesnnaking sure that the mechanism fornnincluding the bets in blocksnnis not eploitablennncreasing efficiency. urrently, the  simulation can handle ~ validators running at the same time (up from ~ a week ago), though ideally we should push this up as much as possible (note that the number of validators the system can handlennon a live networknnshould be roughly the square of the performance of the , as the  runs all nodes on the same machine).nnhe net article in this series will deal with efforts to add a scaffolding for scalability into erenity, and will likely be released around the same time as .