Titre: Validated, staking on eth2: #5 - Why client diversity matters\nAuteur: Carl Beekhuizen\nDate: August 21, 2020\nURL: https://blog.ethereum.org/2020/08/21/validated-why-client-diversity-matters\nCat√©gorie: Non cat√©goris√©\n\n==================================================\n\n*isclaimernnone of this is meant as a slight against any client in particular. here is a high likelihood that each client and possibly even the specification has its own oversights and bugs. th is a complicated protocol, and the people implementing it are only human. he point of this article is to highlight how and why the risks are mitigated.*nnith the launch of the edalla testnet, people were encouraged to eperiment with different clients. nd right from genesis, we saw why imbus and odestar nodes were unable to cope with the workload of a full testnet and got stuck.nn]nn]nns a result, edalla failed to finalise for the first half hour of its eistence.nnn the th of ugust, rysm nodes lost track of time when one of the time servers they were using as a reference suddenly jumped one day into the future. hese nodes then started making blocks and attestations as though they were also in the future. hen the clocks on these nodes were corrected (either by updating the client, or because the timeserver returned to the correct time), those that had disabled the default slashing protection found their stakes slashed.nnactly what happened is a bit more subtle,  highly recommend readingnnaul ordan's write-up of the incidentnn.nnlock ailure - he enworseningnnhe moment when rysm nodes started time traveling, they made up ~% of the network. his meant that the threshold for finalising blocks (/ on one chain) could not be met. orse still, these nodes couldn't find the chain that they were epecting (there was a  hour "gap" in the history and they all jumped ahead to slightly different times) and so they flooded the network with short forks as they guessed at the "missing" data.nnrysm currently makes up % of edalla nodes üò≥ !nnethernodes.org]nnt this point, the network was flooded with thousands of different guesses at what the head of the chain was and all the clients started to buckle under the increased workload of figuring out which chain was the right one. his led to nodes falling behind, needing to sync, running out of memory, and other forms of chaos, all of which worsened the problem.nnltimately this was a good thing, as it allowed us to not only fi the root problem relating to clocks, but to stress test the clients under condition of mass node failure and network load. hat said, this failure need not have been so etreme, and the culprit in this case was rysm's dominance.nnhilling ecentralisation - art , it's good for ethnns 've discussed previouslynn, / is the magic number when it comes to safe, asynchronous  algorithms. f more than / of validators are offline, epochs can no longer be finalised. o while the chain still grows, it is no longer possible to point to a block and guarantee that it will remain a part of the canonical chain.nnhilling ecentralisation - art , it's good for younno the maimum possible etent, validators are incentived to do what is good for the network and not simply trusted to do something because it is the right thing to do.nnf more than / of nodes are offline, then penalties for the offline nodes start ramping up. his is called the inactivity penalty.nnhis means that, as a validator,nnyou want to try to ensure that if something is going to take your node offline, it is unlikely to take many other nodes offline at the same time.nnhe same goes for being slashed.nnhile, there's always a chance that your validators are slashed due to a spec or software mistake/bug, the penalties for single slashings are "only"  .nnowever, if many validators are slashed at the same time as you, then penalties go up to as high as  . he point at which this happens is again the magic / threshold.nnn eplanation of why this is the case can be found here]nn.nnhese incentives are called liveness anti-correlation and safety anti-correlation respectively, and are very intentional aspects of eth's design. nti-correlation mechanisms incentivise validators to make decisions that are in the best interest of the network, by tying individual penalties to how much each validator is impacting the network.nnhilling ecentralisation - art , the numbersnnth is being implemented by many independent teams, each developing independent clients according to thennspecificationnnwritten primarily by the eth research team. his ensures that there are multiple beacon node & validator client implementations, each making different decisions about the technology, languages, optimisations, trade-offs etc required to build an eth client. his way, a bug in any layer of the system will only impact those running a specific client, and not the whole network.nnf, in the eample of the rysm edalla time-bug, only % of eth nodes were running rysm and % of people were online, then the inactivity penalty wouldn't have kicked in for rysm nodes and the problem could have been fied with only minor penalties and some sleepless nights for the devs.nnn contrast, because so many people were running the same client (many of whom had disabled slashing protection), somewhere between  and  validators were slashed in a short period of time.* he high degree of correlation means that slashings were ~  for these validators because they were using a popular client.nn*nnt the time of writing, slashings are still pouring in, so there is no final number yetnn.nnry something newnnow is the time to eperiment with different clients. ind a client that a minority of validators are using, (you can look at the distributionnnherenn).nnighthousenn,nnekunn,nnimbusnn, andnnrysmnnare all reasonably stable at the moment whilennodestarnnis catching up fast.nnost importantly,    ! e have an opportunity to create a more healthy distribution on edalla in preparation for a decentralised mainnet.